"""–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –ø–æ–∫—Ä—ã—Ç–∏—è –¥–æ Senior-—É—Ä–æ–≤–Ω—è.

–≠—Ç–∏ —Ç–µ—Å—Ç—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –ø–æ–Ω–∏–º–∞–Ω–∏–µ edge cases –∏ corner cases.
"""

import numpy as np
import pandas as pd
import pytest


class TestTrainModuleEdgeCases:
    """–¢–µ—Å—Ç—ã –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ –¥–ª—è train –º–æ–¥—É–ª–µ–π."""

    def test_feature_extraction_with_empty_text(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤."""
        from scripts.train_modules.feature_space import NUMERIC_COLS

        df = pd.DataFrame({"reviewText": ["", " ", None, "normal text"]})

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ –ø–∞–¥–∞–µ—Ç –Ω–∞ –ø—É—Å—Ç—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö
        for col in ["text_len", "word_count"]:
            if col in NUMERIC_COLS:
                # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ ‚Äî —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å
                assert "reviewText" in df.columns

    def test_drift_monitor_with_identical_distributions(self):
        """PSI –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 0 –¥–ª—è –∏–¥–µ–Ω—Ç–∏—á–Ω—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π."""
        from scripts.drift_monitor import psi

        data = np.random.normal(0, 1, 1000)
        result = psi(data, data, bins=10)

        assert result < 0.001, "PSI –¥–ª—è –∏–¥–µ–Ω—Ç–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å ~0"

    def test_drift_monitor_with_all_nans(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª—É—á–∞—è, –∫–æ–≥–¥–∞ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è NaN."""
        from scripts.drift_monitor import psi

        expected = np.array([np.nan] * 100)
        actual = np.array([np.nan] * 100)

        # –ù–µ –¥–æ–ª–∂–Ω–æ –ø–∞–¥–∞—Ç—å
        result = psi(expected, actual, bins=5)
        assert not np.isnan(result) or result == 0

    def test_data_validation_with_unicode(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ Unicode —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ."""
        from scripts.data_validation import DataSchema, validate_column_schema

        df = pd.DataFrame(
            {
                "reviewText": [
                    "–û—Ç–ª–∏—á–Ω–∞—è –∫–Ω–∏–≥–∞! üòä",
                    "‰∏≠ÊñáËØÑËÆ∫",
                    "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©",
                    "üî•üî•üî• Amazing!",
                ]
            }
        )

        schema = DataSchema(
            required_columns={"reviewText"},
            optional_columns=set(),
            column_types={},
            numeric_ranges={},
            text_constraints={},
        )

        errors, warnings = validate_column_schema(df, schema)
        assert len(errors) == 0, "Unicode —Å–∏–º–≤–æ–ª—ã –¥–æ–ª–∂–Ω—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"


class TestFeatureContractRobustness:
    """–¢–µ—Å—Ç—ã —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ feature contract."""

    def test_validate_with_extra_columns(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏."""
        from scripts.feature_contract import FeatureContract

        contract = FeatureContract(
            required_text_columns=["reviewText"],
            expected_numeric_columns=["text_len"],
            baseline_stats=None,
        )

        # –î–∞–Ω–Ω—ã–µ —Å extra –∫–æ–ª–æ–Ω–∫–∞–º–∏
        data = {
            "reviewText": "test",
            "text_len": 10.0,
            "unexpected_column": 999,
            "another_extra": "should be ignored",
        }

        warnings = contract.validate_input_data(data)

        # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å warning, –Ω–æ –Ω–µ –ø–∞–¥–∞—Ç—å
        assert isinstance(warnings, dict)

    def test_validate_with_wrong_types(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö."""
        from scripts.feature_contract import FeatureContract

        contract = FeatureContract(
            required_text_columns=["reviewText"],
            expected_numeric_columns=["text_len", "word_count"],
            baseline_stats=None,
        )

        # text_len –ø–µ—Ä–µ–¥–∞–Ω –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞ –≤–º–µ—Å—Ç–æ —á–∏—Å–ª–∞
        data = {"reviewText": "test", "text_len": "not a number", "word_count": 5.0}

        warnings = contract.validate_input_data(data)

        # –î–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å dict (–ø—É—Å—Ç–æ–π –∏–ª–∏ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏)
        assert isinstance(warnings, dict)


class TestDenseTransformerEdgeCases:
    """–ì—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏ –¥–ª—è DenseTransformer."""

    def test_transform_single_row(self):
        """–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
        from scipy.sparse import csr_matrix

        from scripts.train_modules.feature_space import DenseTransformer

        sparse_data = csr_matrix(np.array([[1, 2, 3]]))
        transformer = DenseTransformer()

        result = transformer.fit_transform(sparse_data)

        assert result.shape == (1, 3)
        assert isinstance(result, np.ndarray)

    def test_transform_empty_matrix(self):
        """–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—É—Å—Ç–æ–π –º–∞—Ç—Ä–∏—Ü—ã."""
        from scipy.sparse import csr_matrix

        from scripts.train_modules.feature_space import DenseTransformer

        sparse_data = csr_matrix((0, 5))  # 0 —Å—Ç—Ä–æ–∫, 5 –∫–æ–ª–æ–Ω–æ–∫
        transformer = DenseTransformer()

        result = transformer.fit_transform(sparse_data)

        assert result.shape == (0, 5)


class TestDataValidationCornerCases:
    """Corner cases –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö."""

    def test_validate_with_all_nulls_optional_column(self):
        """–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ —Å–æ –≤—Å–µ–º–∏ NULL –∑–Ω–∞—á–µ–Ω–∏—è–º–∏."""
        from scripts.data_validation import DataSchema, validate_data_quality

        df = pd.DataFrame(
            {"reviewText": ["a", "b", "c"], "optional_field": [None, None, None]}
        )

        schema = DataSchema(
            required_columns={"reviewText"},
            optional_columns={"optional_field"},
            column_types={},
            numeric_ranges={},
            text_constraints={},
        )

        errors, warnings = validate_data_quality(df, schema)

        # –î–ª—è optional –∫–æ–ª–æ–Ω–æ–∫ NULL –¥–æ–ø—É—Å—Ç–∏–º—ã
        assert len([e for e in errors if "optional_field" in e]) == 0

    def test_validate_single_row_dataset(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
        from scripts.data_validation import DataSchema, validate_data_quality

        df = pd.DataFrame({"reviewText": ["single row"], "overall": [5]})

        schema = DataSchema(
            required_columns={"reviewText", "overall"},
            optional_columns=set(),
            column_types={},
            numeric_ranges={},
            text_constraints={},
        )

        errors, warnings = validate_data_quality(df, schema)

        # –ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—à–∏–±–∫–∏ "–¥–∞—Ç–∞—Å–µ—Ç –ø—É—Å—Ç"
        assert not any("–ø—É—Å—Ç" in e.lower() for e in errors)


