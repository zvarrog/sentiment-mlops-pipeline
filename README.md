# Kindle Reviews: Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²

MLOps-Ð¿Ñ€Ð¾ÐµÐºÑ‚ Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³Ð¾Ð² Kindle-Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ‚ÐµÐºÑÑ‚Ð° Ð¸ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð². Ð’ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½ Ð¾Ñ‚ ÑÐ±Ð¾Ñ€Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð¾ Ð¿Ñ€Ð¾Ð´Ð°ÐºÑˆÐ½ API Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð¾Ð¼.

## ðŸ—ï¸ ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°

```text
â”œâ”€â”€ scripts/                    # ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ ÐºÐ¾Ð´
â”‚   â”œâ”€â”€ api_service.py         # FastAPI ÑÐµÑ€Ð²Ð¸Ñ
â”‚   â”œâ”€â”€ train.py               # ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ñ Optuna
â”‚   â”œâ”€â”€ spark_process.py       # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² Spark
â”‚   â”œâ”€â”€ download.py            # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· Kaggle
â”‚   â”œâ”€â”€ drift_monitor.py       # ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð´Ñ€Ð¸Ñ„Ñ‚Ð°
â”‚   â””â”€â”€ models/                # ÐœÐ¾Ð´ÐµÐ»Ð¸ Ð¸ ÑƒÑ‚Ð¸Ð»Ð¸Ñ‚Ñ‹
â”œâ”€â”€ airflow/dags/              # DAG Ð´Ð»Ñ Ð¾Ñ€ÐºÐµÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
â”œâ”€â”€ tests/                     # ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ð¾Ðµ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
â”œâ”€â”€ data/                      # Ð”Ð°Ð½Ð½Ñ‹Ðµ (raw/processed)
â”œâ”€â”€ artefacts/                 # ÐœÐ¾Ð´ÐµÐ»Ð¸ Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
â””â”€â”€ postgres-init/             # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð‘Ð”
```

## ðŸš€ Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ ÑÑ‚Ð°Ñ€Ñ‚

### 1. ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ

```bash
# ÐšÐ»Ð¾Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ
git clone https://github.com/zvarrog/sentiment-mlops-pipeline
cd sentiment-mlops-pipeline

# Ð’Ð¸Ñ€Ñ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ
python -m venv .venv
source .venv/Scripts/activate  # Windows
pip install -r requirements.txt

# Kaggle API (Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…)
# Ð Ð°Ð·Ð¼ÐµÑÑ‚Ð¸Ñ‚Ðµ Ð²Ð°Ñˆ kaggle.json Ð² ÐºÐ¾Ñ€Ð½Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ð¸Ð»Ð¸ Ð¿Ð¾Ð¼ÐµÐ½ÑÐ¹Ñ‚Ðµ Ð¿ÑƒÑ‚ÑŒ Ðº Ð½ÐµÐ¼Ñƒ Ð² .env
```

### 2. Ð—Ð°Ð¿ÑƒÑÐº Ñ‡ÐµÑ€ÐµÐ· Docker Compose

```bash
# ÐŸÐ¾Ð»Ð½Ð°Ñ Ð¸Ð½Ñ„Ñ€Ð°ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° (Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ)
docker compose up -d

# Ð¢Ð¾Ð»ÑŒÐºÐ¾ API
docker compose up -d api postgres

# Ð¢Ð¾Ð»ÑŒÐºÐ¾ Airflow
docker compose up -d airflow postgres
```

- Ð¡Ð¾ÑÑ‚Ð°Ð²: Postgres (Optuna storage), Airflow (Ð¾Ñ€ÐºÐµÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ), API (Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½Ñ).
- MLflow Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð² fileâ€‘Ñ€ÐµÐ¶Ð¸Ð¼Ðµ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ Airflow ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ð° (`/opt/airflow/mlruns`), Ð²Ñ‹Ð½ÐµÑÐµÐ½ Ð½Ð° volume `mlruns_data`.
- UI Ð´Ð»Ñ MLflow Ð½Ðµ Ð¿Ð¾Ð´Ð½Ð¸Ð¼Ð°ÐµÑ‚ÑÑ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑƒÐ¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚ÑŒ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð»ÐµÐ½Ð¸Ðµ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð². ÐŸÑ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¼Ð¾Ð¶Ð½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ ÑÐµÑ€Ð²Ð¸Ñ `mlflow ui` Ð¸Ð»Ð¸ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ UI Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾, ÑƒÐºÐ°Ð·Ð°Ð² `MLFLOW_TRACKING_URI`.
- ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ðµ Airflow, API â€” Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐ° (readâ€‘only, Ð¼Ð¾Ð½Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ÑÑ `./artefacts`).

ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ: Ð² Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ð¸Ð¸ ÑƒÐ¶Ðµ ÐµÑÑ‚ÑŒ baselineâ€‘Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² `artefacts/` â€” API Ð¼Ð¾Ð¶Ð½Ð¾ Ð·Ð°Ð¿ÑƒÑÐºÐ°Ñ‚ÑŒ ÑÑ€Ð°Ð·Ñƒ (Ð±ÐµÐ· Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ). ÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½Ð¾ÑÑ‚Ð¸ â€” Ð² Ñ€Ð°Ð·Ð´ÐµÐ»Ðµ Â«ÐÑ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹ Ð¼Ð¾Ð´ÐµÐ»Ð¸Â» Ð½Ð¸Ð¶Ðµ.

## ðŸ“Š ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹

### âš™ï¸ Airflow DAG

Ð’ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð¾ Ñ‚Ñ€Ð¸ Airflow DAG:

1. **kindle_pipeline.py** â€” Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½
2. **kindle_pipeline_parallel.py** â€” Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (15-20 Ð¼Ð¸Ð½)
3. **kindle_pipeline_monitored.py** â€” Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð² PostgreSQL

**Ð—Ð°Ð¿ÑƒÑÐº:**

```bash
# Ð§ÐµÑ€ÐµÐ· UI: http://localhost:8080 (admin/admin)
# Ð§ÐµÑ€ÐµÐ· CLI:
docker exec -it sentiment-mlops-pipeline-airflow-1 \
  airflow dags trigger kindle_reviews_parallel_pipeline
```

**ÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½Ð°Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ:** `airflow/dags/README_NEW_DAGS.md`, `QUICK_START_NEW_DAGS.md`

### ðŸ¤– ÐœÐ¾Ð´ÐµÐ»Ð¸ Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ

ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ðµ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹:

- **Random Forest** â€” Ð±Ð°Ð·Ð¾Ð²Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ TF-IDF Ð¸ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ð¼Ð¸ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ°Ð¼Ð¸
- **Logistic Regression** â€” Ð±Ñ‹ÑÑ‚Ñ€Ð°Ñ Ð»Ð¸Ð½ÐµÐ¹Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
- **Histogram Gradient Boosting** â€” ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ð³Ñ€Ð°Ð´Ð¸ÐµÐ½Ñ‚Ð½Ñ‹Ð¹ Ð±ÑƒÑÑ‚Ð¸Ð½Ð³
- **MLP** â€” Ð¿Ñ€Ð¾ÑÑ‚Ð°Ñ Ð½ÐµÐ¹Ñ€Ð¾Ð½Ð½Ð°Ñ ÑÐµÑ‚ÑŒ
- **DistilBERT** â€” Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€ Ð´Ð»Ñ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ð³Ð¾ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð°

### ðŸ”§ Ð˜Ð½Ð¶ÐµÐ½ÐµÑ€Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²

**ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼Ñ‹Ðµ:**

- `text_len` â€” Ð´Ð»Ð¸Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ð° Ð² ÑÐ¸Ð¼Ð²Ð¾Ð»Ð°Ñ…
- `word_count` â€” ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ»Ð¾Ð²
- `kindle_freq` â€” Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð° ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ "Kindle"
- `sentiment` â€” Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ (TextBlob)

**Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ (Ð¿Ñ€Ð¸ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ð¸):**

- `user_avg_len`, `user_review_count` â€” Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
- `item_avg_len`, `item_review_count` â€” Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒ Ñ‚Ð¾Ð²Ð°Ñ€Ð°

ÐÐ³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ð¸ user/item (Spark):

- `user_avg_len`, `user_review_count` â€” ÑÑ€ÐµÐ´Ð½ÑÑ Ð´Ð»Ð¸Ð½Ð° Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð² Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸ Ð¸Ñ… ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾
- `item_avg_len`, `item_review_count` â€” ÑÑ€ÐµÐ´Ð½ÑÑ Ð´Ð»Ð¸Ð½Ð° Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð² Ð¿Ð¾ Ñ‚Ð¾Ð²Ð°Ñ€Ñƒ Ð¸ Ð¸Ñ… ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾
- Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÑŽÑ‚ÑÑ Ð² `scripts/spark_process.py` Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑŽÑ‚ÑÑ Ð² parquet; Ð·Ð°Ñ‚ÐµÐ¼ Ð¼Ð¾Ð³ÑƒÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¿ÐµÑ€ÐµÐ´Ð°Ð½Ñ‹ Ð² API Ñ‡ÐµÑ€ÐµÐ· `numeric_features`.

Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ ÐºÐ¾Ð½Ð²ÐµÐ¹ÐµÑ€: TFâ€‘IDF â†’ SVD

- Sparkâ€‘ÑÑ‚Ð°Ð¿: `Tokenizer` â†’ `CountVectorizer` (vocabSize=HASHING_TF_FEATURES, minDF=MIN_DF, minTF=MIN_TF) â†’ `IDF` Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÑ‚ ÑÑ‚Ð¾Ð»Ð±ÐµÑ† `tfidfFeatures` Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¸ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚Ð¾Ð².
- Ð¢Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²ÐºÐ° (sklearn): `TfidfVectorizer` (ngram_range=(1,2), max_features Ð¿Ð¾Ð´Ð±Ð¸Ñ€Ð°ÐµÑ‚ÑÑ Optuna) â†’ Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ `TruncatedSVD`.
- Ð’ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ SVD ÑƒÐ¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ÑÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¿Ð¾ Ð¿Ð°Ð¼ÑÑ‚Ð¸ (`FORCE_SVD_THRESHOLD_MB`) Ð¸Ð»Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð¼ `use_svd` (Optuna). ÐšÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹: `svd_components` (20..100, step=20).

### ðŸŽ¯ ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð³Ð¸Ð¿ÐµÑ€Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²

- **Optuna** Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ð¾Ð´Ð±Ð¾Ñ€Ð° Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²
- **MLflow** Ð´Ð»Ñ Ñ‚Ñ€ÐµÐºÐ¸Ð½Ð³Ð° ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¾Ð²
- **PostgreSQL** Ð´Ð»Ñ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¹
- Ð Ð°Ð½Ð½ÑÑ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ð¸ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ°

## ðŸŒ API

### Ð­Ð½Ð´Ð¿Ð¾Ð¸Ð½Ñ‚Ñ‹

```bash
# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ
GET /health

# ÐœÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
GET /metadata

# ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²
POST /predict
{
  "texts": ["Great product!", "Not satisfied"],
  "numeric_features": {"user_avg_len": [150, 200]}
}

# ÐŸÐ°ÐºÐµÑ‚Ð½Ð¾Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ
POST /batch_predict
{
  "data": [
    {"reviewText": "Amazing!", "user_review_count": 15},
    {"reviewText": "Poor quality", "item_avg_len": 120}
  ]
}
```

ÐÐ³Ñ€ÐµÐ³Ð°Ñ‚Ñ‹ Ð¸ numeric_features Ð² API:

- API Ð¿Ñ€Ð¸Ð½Ð¸Ð¼Ð°ÐµÑ‚ Ð·Ð°Ñ€Ð°Ð½ÐµÐµ Ð¿Ð¾ÑÑ‡Ð¸Ñ‚Ð°Ð½Ð½Ñ‹Ðµ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ð² Ð¿Ð¾Ð»Ðµ `numeric_features` (POST /predict) Ð¸Ð»Ð¸ Ð² ÑÐ¾ÑÑ‚Ð°Ð²Ðµ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð² (POST /batch_predict).
- ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÑŽÑ‚ÑÑ, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: `user_avg_len`, `user_review_count`, `item_avg_len`, `item_review_count`, Ð° Ñ‚Ð°ÐºÐ¶Ðµ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ: `text_len`, `word_count`, `kindle_freq`, `sentiment`.
- Ð•ÑÐ»Ð¸ Ñ‡Ð°ÑÑ‚ÑŒ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð½Ðµ Ð¿ÐµÑ€ÐµÐ´Ð°Ð½Ð°, API Ñ€Ð°ÑÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸; Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚Ñ‹ user/item â€” Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð²Ñ‹ Ð¸Ñ… Ð¿ÐµÑ€ÐµÐ´Ð°Ð´Ð¸Ñ‚Ðµ.
- Ð¡Ð¼. Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ð¸ Ñ‚ÐµÑÑ‚ `tests/test_api_aggregates.py`.

### Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ

- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

### Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ API

Ð”Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ API Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ðµ ÑÐºÑ€Ð¸Ð¿Ñ‚Ñ‹:

```bash
# ÐŸÑ€Ð¾ÑÑ‚Ð¾Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ
python scripts/request.py

# ÐŸÐ°ÐºÐµÑ‚Ð½Ð¾Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ñ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸
python scripts/request_batch.py
```

## ðŸ”„ MLOps Pipeline

### Airflow DAG

ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½ Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚:

1. **Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…** Ð¸Ð· Kaggle
2. **Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ** Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
3. **ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°** Ð² Apache Spark
4. **ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ** Ñ Ð³Ð¸Ð¿ÐµÑ€Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸ÐµÐ¹
5. **Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸** Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ð¾Ð²
6. **ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð´Ñ€Ð¸Ñ„Ñ‚Ð°** Ð´Ð°Ð½Ð½Ñ‹Ñ…

```bash
# Ð—Ð°Ð¿ÑƒÑÐº Ñ‡ÐµÑ€ÐµÐ· Airflow UI
# http://localhost:8080
# admin/admin
```

### Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð·Ð°Ð¿ÑƒÑÐº Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ð°

```bash
# ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½
python scripts/download.py
python scripts/spark_process.py
python scripts/train.py

# ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð´Ñ€Ð¸Ñ„Ñ‚Ð°
python scripts/drift_monitor.py
```

Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…:

- Ð‘Ð°Ð·Ð¾Ð²Ð°Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ csv/parquet Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ Ð² `scripts/data_validation.py` Ð¸ Ð² ÐºÐ¾Ð½Ñ†Ðµ Sparkâ€‘Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ð° (ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº/Ñ‚Ð¸Ð¿Ð¾Ð²/Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ð¾Ð²).
- Ð¤Ð»Ð°Ð³ `RUN_DATA_VALIDATION=1` (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ) Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÑƒ Ð¿Ð¾ÑÐ»Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ parquet.
- ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÑŽÑ‚ÑÑ Ñ‚Ð¸Ð¿Ñ‹, Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ (Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ Sparkâ€‘Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ñ‹Ðµ), Ð½Ð°Ð±Ð¾Ñ€Ñ‹ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹ Ð¸ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ñ‹.

Ð˜Ð½ÑŠÐµÐºÑ†Ð¸Ñ Ð¸ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð´Ñ€ÐµÐ¹Ñ„Ð°:

- Ð˜Ð½ÑŠÐµÐºÑ†Ð¸Ñ: Ð¼Ð¾Ð´ÑƒÐ»ÑŒ `scripts/drift_injection.py` (Ñ„Ð»Ð°Ð³ `INJECT_SYNTHETIC_DRIFT=1`) ÑÐ¸Ð½Ñ‚ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÐ´Ð²Ð¸Ð³Ð°ÐµÑ‚ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… (Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸).
- ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³: `scripts/drift_monitor.py` Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ PSI Ð¿Ð¾ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ð¼ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ°Ð¼, Ð¿Ð¾Ñ€Ð¾Ð³ Ð´Ñ€ÐµÐ¹Ñ„Ð° Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ 0.2; Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑŽÑ‚ÑÑ Ð² `artefacts/drift_artefacts/` (JSON/CSV Ð¸ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¸).
- Ð’ DAG (Airflow): ÑˆÐ°Ð³Ð¸ drift_injection â†’ spark_processing â†’ drift_monitoring Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÑŽÑ‚ Ð¾Ñ‚ÑÐ»ÐµÐ´Ð¸Ñ‚ÑŒ ÑÑ„Ñ„ÐµÐºÑ‚ Ð¸Ð½ÑŠÐµÐºÑ†Ð¸Ð¸.

## ðŸ” ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¸ Ð½Ð°Ð±Ð»ÑŽÐ´Ð°ÐµÐ¼Ð¾ÑÑ‚ÑŒ

### ðŸŽ¯ ÐÐ¾Ð²Ñ‹Ðµ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸

#### ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸

- **Prometheus** ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ API (RPS, latency, errors)
- **Grafana** Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶Ð°ÐµÑ‚ Ð´Ð°ÑˆÐ±Ð¾Ñ€Ð´Ñ‹ Ñ Ð°Ð»ÐµÑ€Ñ‚Ð°Ð¼Ð¸
- Ð”Ð¾ÑÑ‚ÑƒÐ¿: http://localhost:3000 (admin/admin)

#### Drift Alerting

- ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð² Slack Ð¿Ñ€Ð¸ PSI > 0.2
- ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°: ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ `SLACK_WEBHOOK_URL` Ð² `.env`

#### MLflow UI

- ÐŸÑ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ Ð²ÑÐµÑ… ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¾Ð²: http://localhost:5000
- Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹, Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
- Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ð¾Ð² (confusion matrix, feature importances)

### ðŸ“Š Ð”Ð°ÑˆÐ±Ð¾Ñ€Ð´Ñ‹ Grafana

**API Performance:**

- Request rate (Ð¿Ð¾ ÑÐ½Ð´Ð¿Ð¾Ð¸Ð½Ñ‚Ð°Ð¼)
- Response time (p50, p95, p99)
- Error rate
- Active predictions by model

**Model Health:**

- Drift PSI Ð¿Ð¾ Ñ„Ð¸Ñ‡Ð°Ð¼
- Prediction distribution
- Feature importance changes over time

**Infrastructure:**

- CPU/Memory usage
- Disk I/O
- Network traffic

### ðŸš¨ ÐÐ»ÐµÑ€Ñ‚Ð¸Ð½Ð³

ÐÐ°ÑÑ‚Ñ€Ð¾ÐµÐ½Ñ‹ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð°Ð»ÐµÑ€Ñ‚Ñ‹:

| Alert             | Condition                 | Notification                |
| ----------------- | ------------------------- | --------------------------- |
| High Error Rate   | Errors > 1% for 2min      | Slack + Email               |
| High Latency      | p95 > 500ms for 5min      | Slack                       |
| Significant Drift | PSI > 0.2 for any feature | Slack + retrain recommended |
| Low Disk Space    | Free space < 10%          | Email                       |

### Task Performance Monitoring

ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð·Ð°Ð´Ð°Ñ‡ Airflow Ð² PostgreSQL:

```bash
# ÐŸÑ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð·Ð°Ð´Ð°Ñ‡
docker exec -it sentiment-mlops-pipeline-postgres-1 \
  psql -U admin -d metrics -c \
  "SELECT task_id, ROUND(AVG(duration_sec), 2) as avg_sec FROM task_metrics GROUP BY task_id;"
```

**Ð¢Ð°Ð±Ð»Ð¸Ñ†Ñ‹:**

- `task_metrics` â€” Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð·Ð°Ð´Ð°Ñ‡Ð¸
- `model_metrics` â€” Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (F1, accuracy) Ð¿Ð¾ Ð·Ð°Ð¿ÑƒÑÐºÐ°Ð¼

**ÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½ÐµÐµ:** `IMPLEMENTATION_NEW_DAGS.md`

### Drift Detection

- ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ Ð´Ñ€Ð¸Ñ„Ñ‚Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…
- Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ð¹ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
- Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ‚ÐµÑÑ‚Ñ‹ Ð¸ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
- ÐÐ»ÐµÑ€Ñ‚Ñ‹ Ð¿Ñ€Ð¸ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸ÑÑ…

### Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ

Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ trace ID:

```python
from scripts.logging_config import setup_auto_logging
log = setup_auto_logging()
log.info("ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð°", extra={"accuracy": 0.85})
```

### MLflow Tracking

- ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²
- Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¾Ð²
- Ð’ÐµÑ€ÑÐ¸Ð¾Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹

## ðŸ§ª Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ

### Ð—Ð°Ð¿ÑƒÑÐº Ñ‚ÐµÑÑ‚Ð¾Ð²

```bash
# Ð’ÑÐµ Ñ‚ÐµÑÑ‚Ñ‹
python -m pytest tests/ -v

# Smoke Ñ‚ÐµÑÑ‚Ñ‹ API
python -m pytest tests/test_api_smoke.py -v

# Ð¢ÐµÑÑ‚Ñ‹ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
python -m pytest tests/test_*training*.py -v

# E2E Ñ‚ÐµÑÑ‚Ñ‹
python -m pytest tests/test_e2e_smoke.py -v
```

### Ð¢Ð¸Ð¿Ñ‹ Ñ‚ÐµÑÑ‚Ð¾Ð²

- **Unit** â€” Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹
- **Integration** â€” Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¾Ð²
- **E2E** â€” Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½
- **Performance** â€” Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ API
- **Data validation** â€” Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…

## ðŸ“ˆ ÐŸÑ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ

### ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸

- **Ð’ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ** Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¹ Ñ NumPy/Pandas
- **ÐŸÐ°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ñ‹** scikit-learn Ð´Ð»Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
- **ÐšÑÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ** Ð¿Ñ€Ð¾Ð¼ÐµÐ¶ÑƒÑ‚Ð¾Ñ‡Ð½Ñ‹Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
- **ÐŸÐ°Ñ€Ð°Ð»Ð»ÐµÐ»Ð¸Ð·Ð¼** Ð² Optuna Ð¸ Spark

### ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸

- **Accuracy** â€” Ð´Ð¾Ð»Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹
- **F1-score** (macro/weighted) â€” ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°
- **Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ** â€” ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ð°
- **Ð’Ñ€ÐµÐ¼Ñ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐ°** â€” ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ API

## ðŸ”’ Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ

### Production checklist

- [ ] Enable HTTPS (Let's Encrypt)
- [ ] Set up API key authentication
- [ ] Configure firewall (allow only 80, 443, 22)
- [ ] Enable audit logging
- [ ] Rotate secrets monthly
- [ ] Set up VPN for internal services

### Secrets Management

**Development:** `.env` file (gitignored)

**Production:** Kubernetes secrets Ð¸Ð»Ð¸ Vault

```bash
kubectl create secret generic kindle-secrets \
  --from-env-file=.env.prod
```

### API Security Features

- **Rate Limiting:** 100 req/min per IP (slowapi)
- **Graceful Shutdown:** ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð¿Ñ€Ð¸ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐµ
- **Read-only container:** Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ Ñ‡ÐµÑ€ÐµÐ· tmpfs Ð¸ drop capabilities

## âš™ï¸ ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ

### ÐŸÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ

```bash
# Ð”Ð°Ð½Ð½Ñ‹Ðµ
RAW_DATA_DIR=data/raw
PROCESSED_DATA_DIR=data/processed
KAGGLE_DATASET=gunjanbaid/amazon-product-reviews

# ÐœÐ¾Ð´ÐµÐ»Ð¸
MODEL_DIR=artefacts
OPTUNA_N_TRIALS=30
OPTUNA_STORAGE=postgresql://admin:admin@postgres:5432/optuna

# API
API_HOST=0.0.0.0
API_PORT=8000

# Spark
SPARK_DRIVER_MEMORY=4g
SPARK_EXECUTOR_MEMORY=4g
```

### ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð² scripts/settings.py

Ð¦ÐµÐ½Ñ‚Ñ€Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð²ÑÐµÐ¼Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°.

## ðŸ³ Docker

### ÐžÐ±Ñ€Ð°Ð·Ñ‹

```bash
# API ÑÐµÑ€Ð²Ð¸Ñ
docker build -f Dockerfile.api -t kindle-api .

# Airflow Ñ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÑÐ¼Ð¸
docker build -f Dockerfile.airflow -t kindle-airflow .
```

### ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ

```yaml
# docker-compose.yml
services:
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - '8000:8000'
    volumes:
      - ./artefacts:/app/artefacts

  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
```

## ðŸ“Š Ð”Ð°Ð½Ð½Ñ‹Ðµ

### Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº

**Amazon Kindle Reviews** Ñ Kaggle:

- 982,619 Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²
- Ð ÐµÐ¹Ñ‚Ð¸Ð½Ð³Ð¸ 1-5 Ð·Ð²Ñ‘Ð·Ð´
- Ð¢ÐµÐºÑÑ‚ Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²
- ÐœÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹ Ð¸ Ñ‚Ð¾Ð²Ð°Ñ€Ð¾Ð²

### ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°

1. **ÐžÑ‡Ð¸ÑÑ‚ÐºÐ°** â€” ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð² Ð¸ Ð½ÐµÐ²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ñ… Ð·Ð°Ð¿Ð¸ÑÐµÐ¹
2. **Ð‘Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²ÐºÐ°** â€” Ð»Ð¸Ð¼Ð¸Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð½Ð° ÐºÐ»Ð°ÑÑ (35K Ð·Ð°Ð¿Ð¸ÑÐµÐ¹)
3. **Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ** â€” train/val/test (70/15/15%)
4. **ÐŸÑ€Ð¸Ð·Ð½Ð°ÐºÐ¸** â€” Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð¸ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ñ… Ñ„Ð¸Ñ‡ÐµÐ¹

### ÐÑ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹ Ð¼Ð¾Ð´ÐµÐ»Ð¸

Ð”Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° API Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½Ð½Ñ‹Ðµ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹ Ð¼Ð¾Ð´ÐµÐ»Ð¸. Ð’ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ð¸Ð¸ ÑƒÐ¶Ðµ Ð²ÐºÐ»ÑŽÑ‡Ñ‘Ð½ baselineâ€‘Ð½Ð°Ð±Ð¾Ñ€ Ñ„Ð°Ð¹Ð»Ð¾Ð² (ÑÐ¼. Ð¿ÑƒÑ‚Ð¸ Ð½Ð¸Ð¶Ðµ), Ð¿Ð¾ÑÑ‚Ð¾Ð¼Ñƒ Ð¼Ð¾Ð¶Ð½Ð¾ ÑÑ‚Ð°Ñ€Ñ‚Ð¾Ð²Ð°Ñ‚ÑŒ Ð±ÐµÐ· Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ. ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð½Ð°Ð±Ð¾Ñ€:

- `artefacts/best_model.joblib` â€” ÑÐµÑ€Ð¸Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½ Ð¼Ð¾Ð´ÐµÐ»Ð¸
- `artefacts/model_artefacts/best_model_meta.json` â€” Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾ Ð»ÑƒÑ‡ÑˆÐµÐ¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
- `artefacts/model_artefacts/baseline_numeric_stats.json` â€” ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð´Ð»Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸

ÐšÐ°Ðº Ð¾Ð±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹:

1. ÐžÐ±ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾: `python scripts/train.py` â€” Ñ„Ð°Ð¹Ð»Ñ‹ Ð±ÑƒÐ´ÑƒÑ‚ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð² Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ Ð¸Ð· `scripts/settings.py`.
2. Ð¡ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ²Ð¾Ð¸ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹ Ð² ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ðµ Ð¿ÑƒÑ‚Ð¸ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð¸Ð· Ñ€ÐµÐ»Ð¸Ð·Ð°/Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ð¾Ð² CI).
3. ÐŸÑ€Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ð¸ Docker ÑƒÐ±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ `./artefacts` Ð½Ð° Ñ…Ð¾ÑÑ‚Ðµ ÑÐ¼Ð¾Ð½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° Ð² ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ñ‹ API/Airflow.
